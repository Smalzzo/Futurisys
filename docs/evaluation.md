# √âvaluation

## M√©thodologie

- **Split train/test** avec stratification sur `a_quitte_l_entreprise`.
- Sur la partie train :
  - **Validation crois√©e StratifiedKFold** (k=5).
  - Pour chaque fold et chaque mod√®le, on :
    1. Entra√Æne un pipeline complet (pr√©processeur + mod√®le).
    2. Optimise le **seuil F2** sur un sous-split de validation via `precision_recall_curve`.
    3. Applique ce seuil pour calculer les m√©triques sur le fold.
- Le mod√®le retenu est le **GradientBoostingClassifier** avec seuil optimis√©.

Seuil final s√©lectionn√© :

- **Seuil F2 optimal** : `0.12593` (moyenne sur les folds).

---

## M√©triques (validation crois√©e)

Comparaison des principaux mod√®les test√©s (seuil optimis√© par mod√®le) :

- **GradientBoostingClassifier**
  - F2 moyen : **0.65** (‚âà 0.6453)
  - Pr√©cision moyenne : **0.38** (‚âà 0.38)
  - Rappel moyen : **0.79** (‚âà 0.785)
  - Seuil moyen : **0.126**
  - F2_std : ~0.045

- **LogisticRegression**
  - F2 moyen : ~0.64
  - Pr√©cision moyenne : ~0.41
  - Rappel moyen : ~0.74
  - Seuil moyen : ~0.51

- **RandomForestClassifier**
  - F2 moyen : ~0.60
  - Pr√©cision moyenne : ~0.37
  - Rappel moyen : ~0.72
  - Seuil moyen : ~0.17

üëâ Le **GradientBoostingClassifier** avec seuil optimis√© est l√©g√®rement meilleur en F2, et surtout en **rappel**, ce qui est coh√©rent avec l‚Äôobjectif m√©tier (ne pas rater les cas √† risque).

---

## Seuil par d√©faut vs seuil optimis√©

Sur un sc√©nario illustratif (test set) :

- **Seuil par d√©faut (0.5)**  
  - Faux n√©gatifs (FN) : **31**  
  - Beaucoup de d√©parts r√©els ne sont pas d√©tect√©s ‚Üí **rappel faible**.

- **Seuil optimis√© (0.12593)**  
  - Faux n√©gatifs (FN) : **8**  
  - Le nombre de faux n√©gatifs est **divis√© par ~4**.  
  - La pr√©cision diminue, mais le **rappel augmente fortement**.

---

## Matrice de confusion

La matrice de confusion compl√®te (TN, FP, FN, TP) est trac√©e dans le notebook (voir figures ci-dessous) pour le seuil optimis√© :

-![F2/recall/precision](image.png)

![Matrice de confusion](image-1.png)

Points cl√©s :

- Importante **r√©duction des FN** par rapport au seuil 0.5.
- L√©g√®re augmentation des FP, mais acceptable vis-√†-vis du contexte m√©tier (mieux vaut sur-alerter que rater un d√©part probable).

---

## Analyse d‚Äôerreurs

- Les **faux n√©gatifs** restants correspondent souvent √† :
  - des profils ‚Äúinterm√©diaires‚Äù (ni tr√®s satisfaits, ni tr√®s insatisfaits),
  - des historiques atypiques (peu d‚Äôexp√©riences, mais tr√®s bon scoring ailleurs),
  - des cas borderline proches du seuil.

- Les **faux positifs** sont majoritairement des employ√©s :
  - avec signaux de risque (anciennet√© faible, satisfaction moyenne/basse, poste expos√©),
  - mais qui, dans les faits, n‚Äôont pas quitt√© l‚Äôentreprise.

üëâ Dans ce contexte, l‚Äôarbitrage a √©t√© fait en faveur du **rappel** : on accepte davantage de faux positifs pour r√©duire fortement le nombre de d√©parts non d√©tect√©s.
